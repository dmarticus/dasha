{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Gaussian Kernel Density Estimation Fantasy Football Draft Assist Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.distributions.mixture_rvs import mixture_rvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Import and Merging\n",
    "\n",
    "First, I got the raw position data from the following sources:\n",
    "\n",
    "https://fantasy.espn.com/football/players/projections?leagueFormatId=1\n",
    "\n",
    "https://www.fantasysharks.com/apps/Projections/SeasonProjections.php?pos=ALL\n",
    "\n",
    "https://www.fantasypros.com/nfl/rankings/consensus-cheatsheets.php?loggedin=&my-experts=ALL\n",
    "\n",
    "https://fftoolbox.fulltimefantasy.com/football/rankings/index.php?noppr=true\n",
    "\n",
    "https://fantasy.nfl.com/research/projections?position=O&sort=projectedPts&statCategory=projectedStats&statSeason=2020&statType=seasonProjectedStats#researchProjections=researchProjections%2C%2Fresearch%2Fprojections%253Fposition%253DO%2526statCategory%253DprojectedStats%2526statSeason%253D2020%2526statType%253DseasonProjectedStats%2526statWeek%253D1%2Creplace\n",
    "\n",
    "I also got Yahoo!'s draft position list from:\n",
    "https://football.fantasysports.yahoo.com/f1/826195/1/editprerank\n",
    "\n",
    "The scores and ratings from each source are all saved within this repository as individual .xlsx files in the `/raw_data` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I compiled and merged the data using the on player names from the Yahoo! draft list as the primary keys (since I'm going to index DAsHA on the player names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Yahoo! draft positions\n",
    "df = pd.read_excel('./raw_data/Yahoo_2020_Draft_Positions.xlsx')\n",
    "df['Name'] = df['Name'].str.strip() # strip the names so they can be directly compared to other lists\n",
    "\n",
    "# load Fantasy Pros Projections\n",
    "df_fantasy_pros = pd.read_excel('./raw_data/Fantasy_Pros_2020_proj.xlsx')\n",
    "\n",
    "# construct temporary data frame to merge relevant info\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp['Name'] = df_fantasy_pros['PLAYER'].str.strip()\n",
    "df_temp['fp_pts'] = df_fantasy_pros['FAN PTS']\n",
    "\n",
    "# merge df with temporary df\n",
    "df = pd.merge(df, df_temp, on='Name', how ='outer')\n",
    "\n",
    "# import NFL projections\n",
    "df_nfl = pd.read_excel('./raw_data/NFL_2020_proj.xlsx')\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp['Name'] = df_nfl['PLAYER'].str.strip()\n",
    "df_temp['nfl_pts'] = df_nfl['POINTS']\n",
    "\n",
    "df = pd.merge(df, df_temp, on='Name', how ='outer')\n",
    "\n",
    "# import ESPN projections\n",
    "df_espn = pd.read_excel('./raw_data/ESPN_2020_proj.xlsx')\n",
    "\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp['Name'] = df_espn['PLAYER'].str.strip()\n",
    "df_temp['espn_pts'] = df_espn['TOT']\n",
    "\n",
    "df = pd.merge(df, df_temp, on='Name', how ='outer')\n",
    "\n",
    "# import Fantasy Shark projections\n",
    "df_fantasy_shark = pd.read_excel('./raw_data/Fantasy_Shark_2020_proj.xlsx')\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp['Name'] = df_fantasy_shark['Name'].str.strip()\n",
    "df_temp['fs_pts'] = df_fantasy_shark['Fantasy Points']\n",
    "\n",
    "df = pd.merge(df, df_temp, on='Name', how ='outer')\n",
    "\n",
    "# import Sports Illustrated projections\n",
    "df_si = pd.read_excel('./raw_data/Sports_Illustrated_2020_proj.xlsx')\n",
    "\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp['Name'] = df_si['PLAYER'].str.strip()\n",
    "df_temp['si_pts'] = df_si['POINTS']\n",
    "\n",
    "df = pd.merge(df, df_temp, on='Name', how ='outer')\n",
    "\n",
    "# Finally, drop the players not available in Yahoo!\n",
    "df = df.dropna(subset=['Draft Position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Gaussian Kernel Density Estimation\n",
    "\n",
    "Now for the non-parametric fun!\n",
    "\n",
    "I created a Gaussian kernel density estimation for each player using the projected points from each source (NFL, ESPN, Fantasy Sharks, etc.) for the kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty column to store point projections for each player\n",
    "df['pts'] = np.nan\n",
    "\n",
    "# create an empty column to store the inverse cumulative density function data for each player's kde estimation\n",
    "df['kde_icdf'] = [[] for _ in range(len(df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code generates the non-parametric estimations for each player and stores: (1) the median value from the KDE as their projected points and (2) the inverse CDF as an array in kde_icdf so we can generate the non-parametric confidence intervals for the draft tool.\n",
    "\n",
    "This might take a minute or two to run.  I can't be bothered to speed it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Selected KDE bandwidth is 0. Cannot estimate density. Either provide the bandwidth during initialization or use an alternative method.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f8745eda6fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonparametric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKDEUnivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Estimate the densities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mkde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gau'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'silverman'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# This for loop processes to find the median projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/statsmodels/nonparametric/kde.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, kernel, bw, fft, weights, gridsize, adjust, cut, clip)\u001b[0m\n\u001b[1;32m    176\u001b[0m             )\n\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             density, grid, bw = kdensity(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/statsmodels/nonparametric/kde.py\u001b[0m in \u001b[0;36mkdensity\u001b[0;34m(x, kernel, bw, weights, gridsize, adjust, clip, cut, retgrid)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# user passed a callable custom bandwidth function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mbw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbandwidths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0;31m# will cross-val fit this pattern?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/statsmodels/nonparametric/bandwidths.py\u001b[0m in \u001b[0;36mselect_bandwidth\u001b[0;34m(x, bw, kernel)\u001b[0m\n\u001b[1;32m    180\u001b[0m               \u001b[0;34m\"Either provide the bandwidth during initialization or use \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m               \u001b[0;34m\"an alternative method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Selected KDE bandwidth is 0. Cannot estimate density. Either provide the bandwidth during initialization or use an alternative method."
     ]
    }
   ],
   "source": [
    "# start from index 67 because the first 66 entries in my df are contextual cruft and not training data\n",
    "for j in range(66,len(df)):\n",
    "    # this block constructs an array of training data for each player of the different fantasy point estimates. This array is used to generate the KDE.\n",
    "    training_data = []\n",
    "    training_data.append(df['fp_pts'][j])\n",
    "    training_data.append(df['nfl_pts'][j])\n",
    "    training_data.append(df['espn_pts'][j])\n",
    "    training_data.append(df['fs_pts'][j])\n",
    "    training_data.append(df['si_pts'][j])\n",
    "    training_data = [x for x in training_data if str(x) != 'nan'] # clean the training_data for NaN values - which interfere with the analysis below\n",
    "    if len(training_data) == 0:\n",
    "        training_data = [0]\n",
    "    \n",
    "    # this sets up and runs the non-parametric estimation\n",
    "    kde = sm.nonparametric.KDEUnivariate(training_data)\n",
    "    # Estimate the densities\n",
    "    kde.fit(kernel='gau', bw='silverman', fft=False)\n",
    "\n",
    "    # This for loop processes to find the median projection\n",
    "    ci_50 = 0 # initialize median value to zero\n",
    "    for i in range(0, len(kde.cdf)):\n",
    "        if kde.cdf[i] < 0.50:\n",
    "            i+=1\n",
    "        if kde.cdf[i] >= 0.50:\n",
    "            ci_50 = kde.support[i]\n",
    "            break\n",
    "\n",
    "    # Add data to main dataframe\n",
    "    df['pts'][j]=ci_50 # add median projection\n",
    "    df['kde_icdf'][j]=kde.icdf # add icdf for whisker plot construction\n",
    "    \n",
    "# export the dataset to a .csv file so we don't have to run the code above again (it's time consuming!)\n",
    "df.to_csv(r'./prepared_data/2020_ffl_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I included an example of how the KDE estimation works.  `j` represents an arbitrary draft from which we can generate a Gaussian KDE probability density function for the player corresponding to that draft rank.\n",
    "\n",
    "The various point estimates for that player (from ESPN, SI, ets.) are indicated by the red '+'s at the bottom of the graph. What KDE does is to center a normal gaussian distribution (with area = $\\frac{1}{n}$ for n point estimates) over each of thes point estimates. Then, to generate the probabilty density function, we sum all of these \"kernels\" together - this summation is the orange line in the graph below.\n",
    "\n",
    "Then, the following block of code generates a histogram from the KDE PDF showing the 1- and 2- standard deviation confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j = 125\n",
    "\n",
    "training_data = []\n",
    "training_data.append(df['fp_pts'][j])\n",
    "training_data.append(df['nfl_pts'][j])\n",
    "training_data.append(df['espn_pts'][j])\n",
    "training_data.append(df['fs_pts'][j])\n",
    "training_data.append(df['si_pts'][j])\n",
    "training_data = [x for x in training_data if str(x) != 'nan']\n",
    "if len(training_data) == 0:\n",
    "    training_data = [0]\n",
    "    \n",
    "# this sets up and runs the non-parametric estimation\n",
    "kde = sm.nonparametric.KDEUnivariate(training_data)\n",
    "kde.fit(kernel='gau', bw='silverman', fft=False) # Estimate the densities\n",
    "\n",
    "\n",
    "# Note: some plots for the kde visualizations that I'm turning off for the working loops\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Plot the histrogram\n",
    "ax.hist(training_data, bins=5, density=True, label='Histogram from forecasts',\n",
    "        zorder=5, edgecolor='k', alpha=0.5)\n",
    "# Plot the KDE as fitted using the default arguments\n",
    "ax.plot(kde.support, kde.density, lw=3, label='KDE from projections', zorder=10)\n",
    "    \n",
    "# Plot the samples\n",
    "ax.scatter(training_data, np.abs(np.random.randn(len(training_data)))/100000,marker='+', color='red', zorder=20, label='Point Forecasts', alpha=0.5)\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, zorder=-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for confidence interval plots generated from the KDE PDF above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_data=kde.icdf\n",
    "plt.boxplot(box_plot_data, vert=False, labels=[df['Name'][j]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}